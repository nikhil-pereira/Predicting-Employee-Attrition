{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HvvRuJMSzVZ0"
   },
   "source": [
    "# This notebook is set up to run a single data file through developed pipeline that preprocesses, splits, and train/tests data against ML algorithms. The team developed a the tensor flow boosted tree classifier, hyperparameter search on Random Forest, Gradient Boost and Xtreme Gradient Boost and finally Auto Keras. All ML Outputs have a report that shows the ROC curve, confusion matrix, statistical performance metrics and finally the feature importance visuals.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFQ9YscS0Puv"
   },
   "source": [
    "# Data for this notebook is stored in the Client Data directory of VTSD21's Google Drive and can be accessed when that folder is made a shortcut to the user's personal drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ia9-HzAfQ8Wp"
   },
   "source": [
    "# Authorization and accessing the data from the Client Data Folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xqTsHFnHT6SJ"
   },
   "source": [
    "\n",
    "# Security Access and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5000,
     "status": "ok",
     "timestamp": 1618289408957,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "8u3Z2zCH_6sA"
   },
   "outputs": [],
   "source": [
    "# Code to read csv file into colaboratory:\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25168,
     "status": "ok",
     "timestamp": 1618289429151,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "yU0YpnzsEEoq",
    "outputId": "27ca7dbe-b5a0-4b49-bfeb-e9e4e82b76bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 12058,
     "status": "ok",
     "timestamp": 1618289460812,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "sNQAws4QCIDY"
   },
   "outputs": [],
   "source": [
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9841,
     "status": "ok",
     "timestamp": 1618289478368,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "W9GP3ymSFng9",
    "outputId": "401bbb1c-1706-4f27-ce7f-62bb9a7f41f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\r",
      "\u001b[K     |█████▏                          | 10kB 18.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 20kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 30kB 17.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 40kB 10.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 51kB 8.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 61kB 9.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 71kB 4.4MB/s \n",
      "\u001b[?25h  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting autokeras\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/12/cf698586ccc8245f08d1843dcafb65b064a2e9e2923b889dc58e1019f099/autokeras-1.0.12-py3-none-any.whl (164kB)\n",
      "\u001b[K     |████████████████████████████████| 174kB 8.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from autokeras) (0.22.2.post1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from autokeras) (1.1.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from autokeras) (20.9)\n",
      "Requirement already satisfied: tensorflow>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from autokeras) (2.4.1)\n",
      "Requirement already satisfied: keras-tuner>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from autokeras) (1.0.2)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->autokeras) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->autokeras) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->autokeras) (1.19.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->autokeras) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->autokeras) (2.8.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->autokeras) (2.4.7)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (1.1.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (1.12.1)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (0.3.3)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (3.7.4.3)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (1.12)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (3.3.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (1.15.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (0.36.2)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (2.10.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (2.4.0)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (1.32.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (3.12.4)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (1.1.2)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (2.4.1)\n",
      "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (0.12.0)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.0.2->autokeras) (0.4.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.0.2->autokeras) (4.41.1)\n",
      "Requirement already satisfied: terminaltables in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.0.2->autokeras) (3.1.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.0.2->autokeras) (0.16.0)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.0.2->autokeras) (0.8.9)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.0.2->autokeras) (2.23.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow>=2.3.0->autokeras) (54.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (3.3.4)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (1.28.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (1.8.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (0.4.3)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.0.2->autokeras) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.0.2->autokeras) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.0.2->autokeras) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.0.2->autokeras) (2020.12.5)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (3.8.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (4.2.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (3.4.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (3.1.0)\n",
      "Installing collected packages: autokeras\n",
      "Successfully installed autokeras-1.0.12\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U keras-tuner\n",
    "!pip install autokeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 10223,
     "status": "ok",
     "timestamp": 1618289482127,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "a0VagxGxDigq",
    "outputId": "73e2dd44-4e93-4181-abc1-34ff71243984"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import autokeras as ak\n",
    "import kerastuner as kt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Import statements required for Plotly \n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "tf.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HGi0WgjOacH"
   },
   "source": [
    "# Reading in the Data based on 7 files in directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 3912,
     "status": "ok",
     "timestamp": 1618289482132,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "C2oGUE2QIJlS"
   },
   "outputs": [],
   "source": [
    "colab_path = '/content/drive/MyDrive/Client Data/'\n",
    "\n",
    "pathDict = {'K_Survey':'surveywithtarget.csv',\n",
    "            'K_Survey_Org':'surveywithtargetandorg.csv',\n",
    "            'Q1_2018':'bianual_survey_1_2018_processed.csv',\n",
    "            'Q3_2018':'bianual_survey_3_2018_processed.csv',\n",
    "            'Q1_2019':'bianual_survey_1_2019_processed.csv',\n",
    "            'Q3_2019':'bianual_survey_3_2019_processed.csv',\n",
    "            'Q1_2020':'bianual_survey_1_2020_processed.csv'}\n",
    "\n",
    "#consider training on one quarter and then testing on the next quarter\n",
    "\n",
    "def setFilePath(filename):\n",
    "  return pathDict[filename]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28Oq6jeuOf_p"
   },
   "source": [
    "# Call the path of the file you want to read in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "cbe07ec20ce542e4878516d189f8ef49",
      "c96c755a8e3c446a843d3173a02ce48c",
      "24d0e800c9d34745852f3e3ab5cf7520"
     ]
    },
    "executionInfo": {
     "elapsed": 306,
     "status": "ok",
     "timestamp": 1618289485903,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "MVFAiCwGKyGp",
    "outputId": "df565c4a-8751-4179-bc73-ffd784fbad1f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe07ec20ce542e4878516d189f8ef49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='File Name:', options=('K_Survey', 'K_Survey_Org', 'Q1_2018', 'Q3_2018', 'Q1_2019', 'Q3_2…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File set to Q3_2018\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "w = widgets.Dropdown(\n",
    "    options=pathDict.keys(),\n",
    "    description='File Name:',\n",
    "    disabled=False,\n",
    ")\n",
    "def on_change(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        print(\"File set to %s\" % change['new'])\n",
    "        return change\n",
    "\n",
    "w.observe(on_change)\n",
    "display(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 521,
     "status": "ok",
     "timestamp": 1618289493977,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "vvyVwKfo4Wm8"
   },
   "outputs": [],
   "source": [
    "FileName = w.value\n",
    "path = setFilePath(FileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pIW51B9COehR"
   },
   "source": [
    "# Code to handle the nuances of each survey in a general way and format them to fit the ML algos below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 321,
     "status": "ok",
     "timestamp": 1618289496034,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "kdtNUYeWZ5hf"
   },
   "outputs": [],
   "source": [
    "q_cols = ['general empl satisfaction',\n",
    " 'recommend empl unit to friend',\n",
    " 'motivation of direct colleagues you are working with day to day? *Top 3',\n",
    " 'My direct colleagues are coping well with the change and transformation in our division/function',\n",
    " 'People in my team frequently go above and beyond the requirements of the job',\n",
    " 'I am proud working for my company and gladly tell people about it',\n",
    " 'I believe strongly in and support the future direction of my company',\n",
    " 'I trust that my company takes action that balances the best interests of our people, business and clients',\n",
    " \"My company's handling of this year’s challenges leaves me confident in our future success\",\n",
    " \"My company's future direction leaves me confident about my career opportunities here\",\n",
    " 'In my team we continuously use client feedback to improve our products/services',\n",
    " 'In my team we have an ongoing dialogue about our clients and their requirements and expectations',\n",
    " 'Compared to last year, our clients now view us as:',\n",
    " 'My immediate manager creates an atmosphere of openness and trust',\n",
    " 'I have confidence in my immediate manager',\n",
    " 'I have confidence in the global senior management of [division]',\n",
    " 'I have confidence in the senior management of [FUNCTION: Finance, HR, Technology, Operations, Marketing]',\n",
    " 'I have confidence in my local/country senior management',\n",
    " 'As a member of [FUNCTION: Finance, HR, Technology, Operations, Marketing] I am familiar with the overall objectives & strategies of my function',\n",
    " 'I am familiar with the overall objectives & strategies of [division]',\n",
    " 'I can clearly see how my own work contributes to the overall objectives & strategies of [division]',\n",
    " 'In my team we work towards clear objectives',\n",
    " 'In my team we make decisions rapidly when it is necessary',\n",
    " 'In my team actions are taken quickly when decisions have been made',\n",
    " 'Please rate the cooperation between different units within [division]',\n",
    " 'Please rate the cooperation within [FUNCTION: Finance, HR, Technology, Operations, Marketing]',\n",
    " 'Please rate the cooperation across the company as a whole',\n",
    " 'In my team new ideas receive very strong support and encouragement',\n",
    " 'I feel I can make my own decisions concerning my work',\n",
    " \"I have seen action taken based on the results of last year's survey\",\n",
    " 'In my company diversity of skills, experiences, background and ways of working are recognized and appreciated',\n",
    " 'My immediate manager treats all team members fairly, regardless of age, gender identity, sex, family status, race, national origin, nationality, religion, disability or sexual orientation',\n",
    " 'My immediate manager effectively works with people who are different from them to achieve business results',\n",
    " 'In my team we treat each other fairly, regardless of age, sex, gender identity, family status, race, national origin, nationality, religion, disability or sexual orientation',\n",
    " 'I feel included in my team',\n",
    " 'My company takes an interest in my well-being',\n",
    " 'My work schedule allows me sufficient flexibility to meet my personal/family needs',\n",
    " 'Career opportunities always go to the most qualified person regardless of age, gender identity, sex, family status, race, national origin, nationality, religion, disability or sexual orientation',\n",
    " 'Is there anything else you want to share with us?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 531
    },
    "executionInfo": {
     "elapsed": 1674,
     "status": "ok",
     "timestamp": 1618289501505,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "Hh51YEfxKZHU",
    "outputId": "b9096137-24c0-4958-dc4c-c509ea9ca0cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Q3_2018 is formatted correctly for python script\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BusinessUnit</th>\n",
       "      <th>TenureRange</th>\n",
       "      <th>Location</th>\n",
       "      <th>EmployeeType</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Generation</th>\n",
       "      <th>TermType</th>\n",
       "      <th>TermReason</th>\n",
       "      <th>QuarterTermed</th>\n",
       "      <th>DateSurveywasCompleted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GSS</td>\n",
       "      <td>blank</td>\n",
       "      <td>Manila</td>\n",
       "      <td>Contractor</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>8/12/18 17:03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sales</td>\n",
       "      <td>blank</td>\n",
       "      <td>Manila</td>\n",
       "      <td>Contractor</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>8/12/18 17:03</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cloud Operations</td>\n",
       "      <td>blank</td>\n",
       "      <td>Manila</td>\n",
       "      <td>Contractor</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>8/12/18 17:05</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HR</td>\n",
       "      <td>blank</td>\n",
       "      <td>Manila</td>\n",
       "      <td>Contractor</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>8/12/18 17:10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GSS</td>\n",
       "      <td>blank</td>\n",
       "      <td>Manila</td>\n",
       "      <td>Contractor</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>8/12/18 17:10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3545</th>\n",
       "      <td>Innovation</td>\n",
       "      <td>blank</td>\n",
       "      <td>St. Petersburg</td>\n",
       "      <td>Contractor</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3546</th>\n",
       "      <td>Finance</td>\n",
       "      <td>blank</td>\n",
       "      <td>Manila</td>\n",
       "      <td>Contractor</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3547</th>\n",
       "      <td>Sales</td>\n",
       "      <td>blank</td>\n",
       "      <td>Manila</td>\n",
       "      <td>Contractor</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3548</th>\n",
       "      <td>Innovation</td>\n",
       "      <td>blank</td>\n",
       "      <td>St. Petersburg</td>\n",
       "      <td>Contractor</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3549</th>\n",
       "      <td>Innovation</td>\n",
       "      <td>blank</td>\n",
       "      <td>St. Petersburg</td>\n",
       "      <td>Contractor</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3550 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          BusinessUnit TenureRange        Location  ...   20    21 target\n",
       "0                  GSS       blank          Manila  ...  3.0  10.0  False\n",
       "1                Sales       blank          Manila  ...  5.0   9.0  False\n",
       "2     Cloud Operations       blank          Manila  ...  4.0   9.0  False\n",
       "3                   HR       blank          Manila  ...  5.0  11.0  False\n",
       "4                  GSS       blank          Manila  ...  3.0   6.0  False\n",
       "...                ...         ...             ...  ...  ...   ...    ...\n",
       "3545        Innovation       blank  St. Petersburg  ...  0.0   0.0  False\n",
       "3546           Finance       blank          Manila  ...  0.0   0.0  False\n",
       "3547             Sales       blank          Manila  ...  0.0   0.0  False\n",
       "3548        Innovation       blank  St. Petersburg  ...  0.0   0.0  False\n",
       "3549        Innovation       blank  St. Petersburg  ...  0.0   0.0  False\n",
       "\n",
       "[3550 rows x 33 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surveyFile = colab_path + path\n",
    "cat = ['object']\n",
    "num = ['float']\n",
    "if FileName in 'K_Survey' or FileName in 'K_Survey_Org':\n",
    "  surveyPd = pd.read_csv(surveyFile,header=None).fillna(0)\n",
    "  questions = q_cols\n",
    "  #questions = surveyPd.columns \n",
    "  surveyPd.columns = [str(x) for x in list(surveyPd.columns)]\n",
    "elif 'Q' in FileName:\n",
    "  surveyPd = pd.read_csv(surveyFile,header=0,index_col=0)\n",
    "  x1 = surveyPd.select_dtypes(include=cat).fillna('blank').applymap(str)\n",
    "  x2 = surveyPd.select_dtypes(include=num).fillna(0).applymap(float)\n",
    "  x3 = surveyPd[surveyPd.columns[-1]]\n",
    "  surveyPd = pd.concat([x1,x2,x3],axis=1)\n",
    "  import re \n",
    "  #Removing punctuations in string \n",
    "  #Using regex \n",
    "  questions = [str(y) for y in surveyPd.select_dtypes(include=num).columns] #changing this so the categorical column names are included in the questions var\n",
    "  surveyPd.columns = [re.sub(r'[^\\w\\s]', '',s)  for s in list(surveyPd.columns)]\n",
    "  l1 = [x.replace(\" \",\"\") for x in list(surveyPd.select_dtypes(include=cat).columns)]\n",
    "  l2 = [str(y) for y in list(range(len(surveyPd.select_dtypes(include=num).columns)))]\n",
    "  l3 = [surveyPd.columns[-1]]\n",
    "  surveyPd.columns = l1 + l2 + l3\n",
    "target = surveyPd[surveyPd.columns[-1]]\n",
    "if target.dtype != bool:\n",
    "    raise Exception('Last column is not formatted as the Target Boolean Column'.format(target))\n",
    "    print(\"File \" + FileName + \" is formatted incorrectly for python script\")\n",
    "else:\n",
    "    print(\"File \" + FileName + \" is formatted correctly for python script\")\n",
    "surveyPd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 808,
     "status": "ok",
     "timestamp": 1618289506348,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "o4YR92hQ7Xe3",
    "outputId": "700eefcb-b084-4a30-82cd-1466dffbbb26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Leadership clearly communicates the direction in which the company is moving.',\n",
       " 'I am confident about the future performance of the company.',\n",
       " 'I have confidence in the decisions made by the leadership at the company.',\n",
       " 'I have a clear understanding of the priorities for the company.',\n",
       " 'Communication between departments at the company is good.',\n",
       " \"Leadership at my location shares insights and information that makes me feel connected to the company's strategy.\",\n",
       " 'Leadership acts in accordance with the values of the company.',\n",
       " 'The people I work with cooperate to get the job done.',\n",
       " 'My direct manager communicates what is expected of me.',\n",
       " 'My direct manager gives me quarterly feedback on my performance.',\n",
       " 'The feedback I receive from my direct manager helps me improve my performance.',\n",
       " 'My direct manager recognizes me for my contributions on the job.',\n",
       " 'I am comfortable discussing concerns with my direct manager.',\n",
       " 'My job makes good use of my skills and abilities.',\n",
       " 'My direct manager supports my skill and career development.',\n",
       " 'My direct manager encourages an open and collaborative work environment.',\n",
       " 'My direct manager supports my efforts to balance my work and personal life.',\n",
       " \"I am able to provide input on the work I'm responsible for.\",\n",
       " 'I intend to stay with the company for at least the next twelve months.',\n",
       " 'I enjoy working for the company.',\n",
       " 'I enjoy working on my day to day tasks and assignments.',\n",
       " 'How likely is it you would recommend the company as a good place to work?']"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nyj-xg_lOMll"
   },
   "source": [
    "# Code to preprocess columns that are mostly blank by dropping columns if the average non-blanks is less than a specific threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 299,
     "status": "ok",
     "timestamp": 1618289509640,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "ojm76aI-rHdH"
   },
   "outputs": [],
   "source": [
    "threshold = 0.3\n",
    "droplist = []\n",
    "for col in list(surveyPd.select_dtypes(include = num)):\n",
    "  if (surveyPd[col] > 0).mean() < threshold:\n",
    "    droplist.append(col)\n",
    "    surveyPd = surveyPd.drop(col,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYOIsiN0PSd5"
   },
   "source": [
    "# Columns that were dropped because mostly blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1618289511497,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "2_zD7wpiN_At",
    "outputId": "59716ad8-1bb0-45ce-cab5-79e72446bda8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "droplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 458,
     "status": "ok",
     "timestamp": 1618289513518,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "1cT1zUg0vYKG"
   },
   "outputs": [],
   "source": [
    "#using sklearn to split the data\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, plot_confusion_matrix, plot_precision_recall_curve, plot_roc_curve\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(surveyPd.iloc[:,0:-1], target, test_size=0.2, random_state = 42) #need to change this if we want to only include questions\n",
    "#right now this is including all of the categorical columns for the datasets from Company #2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dcUDSnbFpYM"
   },
   "source": [
    "# Running Tensor Flow's Gradient Boost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5j4V4lJqq57B"
   },
   "source": [
    "# Pre Processing Data Using One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42784,
     "status": "aborted",
     "timestamp": 1618289446830,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "FvYydksjq-lL"
   },
   "outputs": [],
   "source": [
    "fc = tf.feature_column\n",
    "cat = ['object']\n",
    "num = ['float']\n",
    "CATEGORICAL_COLUMNS = surveyPd.select_dtypes(include=cat).columns\n",
    "NUMERIC_COLUMNS = surveyPd.select_dtypes(include=num).columns\n",
    "\n",
    "def one_hot_cat_column(feature_name, vocab):\n",
    "  return fc.indicator_column(\n",
    "      fc.categorical_column_with_vocabulary_list(feature_name,\n",
    "                                                 vocab))\n",
    "feature_columns = []\n",
    "for feature_name in CATEGORICAL_COLUMNS:\n",
    "  # Need to one-hot encode categorical features.\n",
    "  vocabulary = X_train[feature_name].unique()\n",
    "  feature_columns.append(one_hot_cat_column(feature_name, vocabulary))\n",
    "\n",
    "for feature_name in NUMERIC_COLUMNS:\n",
    "  feature_columns.append(fc.numeric_column(feature_name,\n",
    "                                           dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zDfV4Wc3ygYo"
   },
   "source": [
    "# Build the input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 295,
     "status": "ok",
     "timestamp": 1618289527751,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "uHYKgUw4xSif"
   },
   "outputs": [],
   "source": [
    "# Use entire batch since this is such a small dataset.\n",
    "NUM_EXAMPLES = len(y_train)\n",
    "\n",
    "def make_input_fn(X, y, n_epochs=None, shuffle=True):\n",
    "  def input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X.to_dict(orient='list'), y))\n",
    "    if shuffle:\n",
    "      dataset = dataset.shuffle(NUM_EXAMPLES)\n",
    "    # For training, cycle thru dataset as many times as need (n_epochs=None).\n",
    "    dataset = (dataset\n",
    "      .repeat(n_epochs)\n",
    "      .batch(NUM_EXAMPLES))\n",
    "    return dataset\n",
    "  return input_fn\n",
    "\n",
    "# Training and evaluation input functions.\n",
    "train_input_fn = make_input_fn(X_train, y_train)\n",
    "eval_input_fn = make_input_fn(X_test, y_test, shuffle=False, n_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1VMUdzRyx1G"
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "executionInfo": {
     "elapsed": 530,
     "status": "error",
     "timestamp": 1618289530486,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "-gB3R6o1xtof",
    "outputId": "13c3e02c-38b2-42ac-8a6f-c9c32dd9f134"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-7b131556b8d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m }\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBoostedTreesClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m# Train model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feature_columns' is not defined"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "  'n_trees': 50,\n",
    "  'max_depth': 3,\n",
    "  'n_batches_per_layer': 1,\n",
    "  # You must enable center_bias = True to get DFCs. This will force the model to\n",
    "  # make an initial prediction before using any features (e.g. use the mean of\n",
    "  # the training labels for regression or log odds for classification when\n",
    "  # using cross entropy loss).\n",
    "  'center_bias': True\n",
    "}\n",
    "\n",
    "est = tf.estimator.BoostedTreesClassifier(feature_columns, **params)\n",
    "# Train model.\n",
    "est.train(train_input_fn, max_steps=100)\n",
    "\n",
    "# Evaluation.\n",
    "results = est.evaluate(eval_input_fn)\n",
    "#clear_output()\n",
    "pd.Series(results).to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWZoJ3Kqy2Z5"
   },
   "source": [
    "For performance reasons, when your data fits in memory, we recommend use the arg train_in_memory=True in the tf.estimator.BoostedTreesClassifier function. However if training time is not of a concern or if you have a very large dataset and want to do distributed training, use the tf.estimator.BoostedTrees API shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42768,
     "status": "aborted",
     "timestamp": 1618289446832,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "fI15DTcP76qc"
   },
   "outputs": [],
   "source": [
    "in_memory_params = dict(params)\n",
    "in_memory_params['n_batches_per_layer'] = 1\n",
    "# In-memory input_fn does not use batching.\n",
    "def make_inmemory_train_input_fn(X, y):\n",
    "  y = np.expand_dims(y, axis=1)\n",
    "  def input_fn():\n",
    "    return dict(X), y\n",
    "  return input_fn\n",
    "train_input_fn = make_inmemory_train_input_fn(X_train, y_train) #Do we need to restrict to the questions?\n",
    "\n",
    "# Train the model.\n",
    "est = tf.estimator.BoostedTreesClassifier(\n",
    "    feature_columns, \n",
    "    train_in_memory=True, \n",
    "    **in_memory_params)\n",
    "\n",
    "est.train(train_input_fn)\n",
    "# Evaluation.\n",
    "results = est.evaluate(eval_input_fn)\n",
    "#clear_output()\n",
    "pd.Series(results).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42764,
     "status": "aborted",
     "timestamp": 1618289446833,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "QEfB1qEz4G8V"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns_colors = sns.color_palette('colorblind')\n",
    "pred_dicts = list(est.experimental_predict_with_explanations(eval_input_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8tjuU-QvzDWk"
   },
   "source": [
    "# Feature Importance and Model Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42762,
     "status": "aborted",
     "timestamp": 1618289446833,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "E2zYauIncmRV"
   },
   "outputs": [],
   "source": [
    "importances = est.experimental_feature_importances(normalize=True)\n",
    "df_imp = pd.Series(importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAqxTmEAzZM8"
   },
   "source": [
    "# Plot Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42757,
     "status": "aborted",
     "timestamp": 1618289446835,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "d_Fo0zFy1PFW"
   },
   "outputs": [],
   "source": [
    "# Scatter plot \n",
    "trace = go.Scatter(\n",
    "    y = df_imp.values,\n",
    "    x = df_imp.index,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        sizemode = 'diameter',\n",
    "        sizeref = 1,\n",
    "        size = 13,\n",
    "        #size= rf.feature_importances_,\n",
    "        #color = np.random.randn(500), #set color equal to a variable\n",
    "        color = df_imp.values,\n",
    "        colorscale='Portland',\n",
    "        showscale=True\n",
    "    ),\n",
    "    text = surveyPd.columns.values\n",
    ")\n",
    "data = [trace]\n",
    "\n",
    "layout= go.Layout(\n",
    "    autosize= True,\n",
    "    title= 'Tensor Flow Gradient Boost Feature Importance',\n",
    "    hovermode= 'closest',\n",
    "     xaxis= dict(\n",
    "         ticklen= 1,\n",
    "         showgrid=False,\n",
    "        zeroline=False,\n",
    "        showline=False\n",
    "     ),\n",
    "    yaxis=dict(\n",
    "        title= 'Feature Importance',\n",
    "        showgrid=False,\n",
    "        zeroline=False,\n",
    "        ticklen= 5,\n",
    "        gridwidth= 2\n",
    "    ),\n",
    "    showlegend= False\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig,filename='scatterrf1')\n",
    "fig.show(renderer=\"colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42754,
     "status": "aborted",
     "timestamp": 1618289446836,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "yGi5iC1BDzud"
   },
   "outputs": [],
   "source": [
    "#Here are the most important questions according to the GB algorithm\n",
    "\n",
    "gb_importances = df_imp.values\n",
    "gb_index = df_imp.index\n",
    "new_index = gb_index\n",
    "\n",
    "featureimportance_gb = pd.DataFrame({'Question Number': new_index, 'Feature Importance': gb_importances}, columns=['Question Number', 'Feature Importance'])\n",
    "gb_df = featureimportance_gb.sort_values(by=['Feature Importance'], ascending=False)\n",
    "gb_df\n",
    "\n",
    "gb_five = gb_df.head(n=5)\n",
    "print(gb_five)\n",
    "\n",
    "question_column = gb_five.loc[:,'Question Number']\n",
    "\n",
    "imp_gb_questions = question_column.values\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42748,
     "status": "aborted",
     "timestamp": 1618289446836,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "9DDzYobmEyjG"
   },
   "outputs": [],
   "source": [
    "#returning the 5 most important questions\n",
    "\n",
    "print(\"The most important factors/questions are:  \\n\", imp_gb_questions)\n",
    "\n",
    "# for i in imp_gb_questions:\n",
    "#   print(questions[int(i)]) #q_cols is for company #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRPdrQ92LHGI"
   },
   "source": [
    "# Logit Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 263,
     "status": "ok",
     "timestamp": 1618289569783,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "4g2UpTVoLJ-T",
    "outputId": "6184dc47-6e69-4de6-da31-8b93c7588a38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#consider normalizing the scores with z-scores- only use training set, not the test \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train.select_dtypes(include=num), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1618289571932,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "CuiOY-HYLTK7",
    "outputId": "9b084a9b-898f-4360-e135-202dc0f593ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.99\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(X_test.select_dtypes(include=num))\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test.select_dtypes(include=num), y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "executionInfo": {
     "elapsed": 294,
     "status": "error",
     "timestamp": 1618289574019,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "nxdtylzpLZdF",
    "outputId": "a977bd91-1b15-431f-e1df-76119d2021b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[706   0]\n",
      " [  4   0]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-856dabcca5ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myticklabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxticklabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"g\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'label_names' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)\n",
    "\n",
    "sns.heatmap(confusion_matrix, annot=True, yticklabels=label_names, xticklabels=label_names, fmt=\"g\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42730,
     "status": "aborted",
     "timestamp": 1618289446838,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "CUmi59teLcrn"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42732,
     "status": "aborted",
     "timestamp": 1618289446847,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "GPUlNm33Lxc2"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test.select_dtypes(include=num)))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test.select_dtypes(include=num))[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uEzxc58AT70I"
   },
   "source": [
    "# Machine Learning Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KjMTZqgInPv-"
   },
   "source": [
    "# Hyper Parameter Search using Sklearn Grid Search Method for RF,\n",
    "Does RF only take numeric inputs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 63873,
     "status": "ok",
     "timestamp": 1618289655506,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "kKN2Z3iwk66C"
   },
   "outputs": [],
   "source": [
    "#Try different loss functions check sample weight too\n",
    "import sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "rf_parameters = {'n_jobs':[1], \n",
    "                 'max_depth':[3,5],\n",
    "                 'min_samples_split':[0.05], \n",
    "                 'class_weight':[\"balanced\",'balanced_subsample'],\n",
    "                 'n_estimators':[50,100,500],\n",
    "                 'max_features':[0.3,'auto'], \n",
    "                 'random_state':[42]\n",
    "                 }\n",
    "svc = sklearn.ensemble.RandomForestClassifier()\n",
    "clf = GridSearchCV(svc, rf_parameters)\n",
    "clf.fit(X_train.select_dtypes(include=num), y_train)\n",
    "rf_results = pd.DataFrame.from_dict(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jV7OvbL2H7Pq"
   },
   "source": [
    "# Random Forest Hyper Parameter Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 316,
     "status": "ok",
     "timestamp": 1618289819015,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "pDadOowcQui3",
    "outputId": "a7621eeb-9e6f-4792-941a-5d4e85734b54"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_weight</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>n_jobs</th>\n",
       "      <th>random_state</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_n_jobs</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>balanced</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.05</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0.935963</td>\n",
       "      <td>0.009053</td>\n",
       "      <td>0.058562</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>balanced</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.05</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'class_weight': 'balanced', 'max_depth': 5, '...</td>\n",
       "      <td>0.955986</td>\n",
       "      <td>0.966549</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.970070</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>0.970070</td>\n",
       "      <td>0.009643</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0.271062</td>\n",
       "      <td>0.006120</td>\n",
       "      <td>0.013102</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'class_weight': 'balanced_subsample', 'max_de...</td>\n",
       "      <td>0.955986</td>\n",
       "      <td>0.959507</td>\n",
       "      <td>0.970070</td>\n",
       "      <td>0.975352</td>\n",
       "      <td>0.989437</td>\n",
       "      <td>0.970070</td>\n",
       "      <td>0.011941</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>balanced</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0.208009</td>\n",
       "      <td>0.008184</td>\n",
       "      <td>0.014103</td>\n",
       "      <td>0.001385</td>\n",
       "      <td>balanced</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'class_weight': 'balanced', 'max_depth': 5, '...</td>\n",
       "      <td>0.955986</td>\n",
       "      <td>0.959507</td>\n",
       "      <td>0.970070</td>\n",
       "      <td>0.977113</td>\n",
       "      <td>0.987676</td>\n",
       "      <td>0.970070</td>\n",
       "      <td>0.011572</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.05</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>1.332205</td>\n",
       "      <td>0.012672</td>\n",
       "      <td>0.063359</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.05</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'class_weight': 'balanced_subsample', 'max_de...</td>\n",
       "      <td>0.955986</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.970070</td>\n",
       "      <td>0.987676</td>\n",
       "      <td>0.970070</td>\n",
       "      <td>0.010386</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0.283162</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>0.014414</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'class_weight': 'balanced_subsample', 'max_de...</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.963028</td>\n",
       "      <td>0.966549</td>\n",
       "      <td>0.977113</td>\n",
       "      <td>0.984155</td>\n",
       "      <td>0.969718</td>\n",
       "      <td>0.009604</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>balanced</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0.191180</td>\n",
       "      <td>0.010025</td>\n",
       "      <td>0.013716</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>balanced</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'class_weight': 'balanced', 'max_depth': 5, '...</td>\n",
       "      <td>0.955986</td>\n",
       "      <td>0.955986</td>\n",
       "      <td>0.973592</td>\n",
       "      <td>0.973592</td>\n",
       "      <td>0.987676</td>\n",
       "      <td>0.969366</td>\n",
       "      <td>0.012075</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>balanced</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>1.007239</td>\n",
       "      <td>0.010538</td>\n",
       "      <td>0.062341</td>\n",
       "      <td>0.004164</td>\n",
       "      <td>balanced</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'class_weight': 'balanced', 'max_depth': 5, '...</td>\n",
       "      <td>0.948944</td>\n",
       "      <td>0.970070</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.977113</td>\n",
       "      <td>0.984155</td>\n",
       "      <td>0.969014</td>\n",
       "      <td>0.011972</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.05</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0.141690</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.007735</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.05</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'class_weight': 'balanced_subsample', 'max_de...</td>\n",
       "      <td>0.955986</td>\n",
       "      <td>0.959507</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.966549</td>\n",
       "      <td>0.987676</td>\n",
       "      <td>0.968310</td>\n",
       "      <td>0.011135</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>1.410325</td>\n",
       "      <td>0.016891</td>\n",
       "      <td>0.060058</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'class_weight': 'balanced_subsample', 'max_de...</td>\n",
       "      <td>0.948944</td>\n",
       "      <td>0.966549</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.977113</td>\n",
       "      <td>0.984155</td>\n",
       "      <td>0.968310</td>\n",
       "      <td>0.011993</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>balanced</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.05</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0.095465</td>\n",
       "      <td>0.002156</td>\n",
       "      <td>0.007429</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>balanced</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.05</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'class_weight': 'balanced', 'max_depth': 5, '...</td>\n",
       "      <td>0.955986</td>\n",
       "      <td>0.952465</td>\n",
       "      <td>0.970070</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.987676</td>\n",
       "      <td>0.967606</td>\n",
       "      <td>0.012578</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>balanced</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0.103816</td>\n",
       "      <td>0.002354</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>balanced</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'class_weight': 'balanced', 'max_depth': 5, '...</td>\n",
       "      <td>0.948944</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.959507</td>\n",
       "      <td>0.977113</td>\n",
       "      <td>0.989437</td>\n",
       "      <td>0.966549</td>\n",
       "      <td>0.014646</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0.144356</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>0.008287</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'class_weight': 'balanced_subsample', 'max_de...</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.959507</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.982394</td>\n",
       "      <td>0.964437</td>\n",
       "      <td>0.011268</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>balanced</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0.101791</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>balanced</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'class_weight': 'balanced', 'max_depth': 3, '...</td>\n",
       "      <td>0.908451</td>\n",
       "      <td>0.919014</td>\n",
       "      <td>0.906690</td>\n",
       "      <td>0.883803</td>\n",
       "      <td>0.984155</td>\n",
       "      <td>0.920423</td>\n",
       "      <td>0.033872</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>balanced</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0.199204</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.013461</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>balanced</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'class_weight': 'balanced', 'max_depth': 3, '...</td>\n",
       "      <td>0.913732</td>\n",
       "      <td>0.904930</td>\n",
       "      <td>0.927817</td>\n",
       "      <td>0.869718</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.917606</td>\n",
       "      <td>0.033207</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0.140944</td>\n",
       "      <td>0.010111</td>\n",
       "      <td>0.007631</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'class_weight': 'balanced_subsample', 'max_de...</td>\n",
       "      <td>0.919014</td>\n",
       "      <td>0.899648</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.866197</td>\n",
       "      <td>0.980634</td>\n",
       "      <td>0.916197</td>\n",
       "      <td>0.037241</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0.270373</td>\n",
       "      <td>0.011152</td>\n",
       "      <td>0.013186</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'class_weight': 'balanced_subsample', 'max_de...</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.882042</td>\n",
       "      <td>0.927817</td>\n",
       "      <td>0.855634</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.910563</td>\n",
       "      <td>0.039765</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>balanced</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.05</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0.092220</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>0.008248</td>\n",
       "      <td>0.002098</td>\n",
       "      <td>balanced</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.05</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'class_weight': 'balanced', 'max_depth': 3, '...</td>\n",
       "      <td>0.908451</td>\n",
       "      <td>0.857394</td>\n",
       "      <td>0.929577</td>\n",
       "      <td>0.873239</td>\n",
       "      <td>0.975352</td>\n",
       "      <td>0.908803</td>\n",
       "      <td>0.041876</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>balanced</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.05</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0.903493</td>\n",
       "      <td>0.011105</td>\n",
       "      <td>0.060371</td>\n",
       "      <td>0.004661</td>\n",
       "      <td>balanced</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.05</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'class_weight': 'balanced', 'max_depth': 3, '...</td>\n",
       "      <td>0.883803</td>\n",
       "      <td>0.869718</td>\n",
       "      <td>0.933099</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.973592</td>\n",
       "      <td>0.907042</td>\n",
       "      <td>0.040169</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.05</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0.134390</td>\n",
       "      <td>0.003503</td>\n",
       "      <td>0.007191</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.05</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'class_weight': 'balanced_subsample', 'max_de...</td>\n",
       "      <td>0.913732</td>\n",
       "      <td>0.862676</td>\n",
       "      <td>0.920775</td>\n",
       "      <td>0.846831</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.903169</td>\n",
       "      <td>0.044609</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.05</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>1.292122</td>\n",
       "      <td>0.021341</td>\n",
       "      <td>0.057501</td>\n",
       "      <td>0.001511</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.05</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'class_weight': 'balanced_subsample', 'max_de...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.866197</td>\n",
       "      <td>0.933099</td>\n",
       "      <td>0.864437</td>\n",
       "      <td>0.970070</td>\n",
       "      <td>0.901761</td>\n",
       "      <td>0.042479</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>balanced</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0.948771</td>\n",
       "      <td>0.005259</td>\n",
       "      <td>0.056381</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>balanced</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'class_weight': 'balanced', 'max_depth': 3, '...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.869718</td>\n",
       "      <td>0.927817</td>\n",
       "      <td>0.866197</td>\n",
       "      <td>0.968310</td>\n",
       "      <td>0.901408</td>\n",
       "      <td>0.040286</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>balanced</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0.186595</td>\n",
       "      <td>0.008273</td>\n",
       "      <td>0.013238</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>balanced</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'class_weight': 'balanced', 'max_depth': 3, '...</td>\n",
       "      <td>0.883803</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.929577</td>\n",
       "      <td>0.866197</td>\n",
       "      <td>0.975352</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.046851</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0.257393</td>\n",
       "      <td>0.006698</td>\n",
       "      <td>0.013457</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'class_weight': 'balanced_subsample', 'max_de...</td>\n",
       "      <td>0.889085</td>\n",
       "      <td>0.855634</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.852113</td>\n",
       "      <td>0.973592</td>\n",
       "      <td>0.897183</td>\n",
       "      <td>0.044714</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>1.346089</td>\n",
       "      <td>0.012383</td>\n",
       "      <td>0.059608</td>\n",
       "      <td>0.003573</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'class_weight': 'balanced_subsample', 'max_de...</td>\n",
       "      <td>0.864437</td>\n",
       "      <td>0.862676</td>\n",
       "      <td>0.926056</td>\n",
       "      <td>0.855634</td>\n",
       "      <td>0.968310</td>\n",
       "      <td>0.895423</td>\n",
       "      <td>0.044422</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          class_weight  max_depth  ... std_test_score  rank_test_score\n",
       "11            balanced          5  ...       0.009643                1\n",
       "22  balanced_subsample          5  ...       0.011941                1\n",
       "7             balanced          5  ...       0.011572                1\n",
       "23  balanced_subsample          5  ...       0.010386                1\n",
       "19  balanced_subsample          5  ...       0.009604                5\n",
       "10            balanced          5  ...       0.012075                6\n",
       "8             balanced          5  ...       0.011972                7\n",
       "21  balanced_subsample          5  ...       0.011135                8\n",
       "20  balanced_subsample          5  ...       0.011993                8\n",
       "9             balanced          5  ...       0.012578               10\n",
       "6             balanced          5  ...       0.014646               11\n",
       "18  balanced_subsample          5  ...       0.011268               12\n",
       "0             balanced          3  ...       0.033872               13\n",
       "1             balanced          3  ...       0.033207               14\n",
       "12  balanced_subsample          3  ...       0.037241               15\n",
       "13  balanced_subsample          3  ...       0.039765               16\n",
       "3             balanced          3  ...       0.041876               17\n",
       "5             balanced          3  ...       0.040169               18\n",
       "15  balanced_subsample          3  ...       0.044609               19\n",
       "17  balanced_subsample          3  ...       0.042479               20\n",
       "2             balanced          3  ...       0.040286               21\n",
       "4             balanced          3  ...       0.046851               22\n",
       "16  balanced_subsample          3  ...       0.044714               23\n",
       "14  balanced_subsample          3  ...       0.044422               24\n",
       "\n",
       "[24 rows x 27 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf = pd.DataFrame.from_dict(clf.cv_results_['params'])\n",
    "result = pd.concat([newdf,rf_results], axis=1, join='inner')\n",
    "result.sort_values('rank_test_score', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UNetC7leG-as"
   },
   "source": [
    "# Using the best results of the Hyper Parameter Search on the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sGLV1YJPmehy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "executionInfo": {
     "elapsed": 590,
     "status": "error",
     "timestamp": 1618290230202,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "Ay29ebw7xd9S",
    "outputId": "cf2e32aa-a382-4acf-81a5-f9c636cefef6"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-526422427715>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#ROC Curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mRF_roc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'roc_auc_score' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, plot_confusion_matrix, plot_precision_recall_curve, plot_roc_curve\n",
    "\n",
    "clf1 = RandomForestClassifier(**clf.best_params_) #defining the algorithm\n",
    "#Fitting the Data\n",
    "clf1.fit(X_train.select_dtypes(include=num), y_train)\n",
    "\n",
    "\n",
    "#ROC Curve\n",
    "RF_roc_auc = roc_auc_score(y_test, clf1.predict(X_test.select_dtypes(include=num)))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, clf1.predict_proba(X_test.select_dtypes(include=num))[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Random Forest (area = %0.2f)' % RF_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('RF_ROC')\n",
    "plt.show()\n",
    "\n",
    "#defining the predicted data and the list for the label names\n",
    "y_pred = clf1.predict(X_test.select_dtypes(include=num))\n",
    "label_names=['Stayed','Attrited']\n",
    "\n",
    "#Creating the confustion matrix\n",
    "cf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cf_matrix, annot=True, yticklabels=label_names, xticklabels=label_names, fmt=\"g\")\n",
    "\n",
    "#Creating confustion matrix for the train set\n",
    "#cf1_matrix = metrics.confusion_matrix(y_train, clf1.predict(X_train.select_dtypes(include=num)))\n",
    "#sns.heatmap(cf1_matrix, annot=True, yticklabels=label_names, xticklabels=label_names, fmt=\"g\")\n",
    "\n",
    "#Creating the full statistical report for the train set   \n",
    "print(classification_report(y_test, y_pred, target_names=label_names))\n",
    "\n",
    "# #Classification report for the test set\n",
    "# print(classification_report(y_train, clf1.predict(X_train.select_dtypes(include=num))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZMYZt5kHmP1"
   },
   "source": [
    "# Scatter Plot of Feature Importance Determined from RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42714,
     "status": "aborted",
     "timestamp": 1618289446849,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "1wgHdu4uxLAm"
   },
   "outputs": [],
   "source": [
    "# Scatter plot \n",
    "trace = go.Scatter(\n",
    "    y = clf1.feature_importances_,\n",
    "    x = surveyPd.columns.values,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        sizemode = 'diameter',\n",
    "        sizeref = 1,\n",
    "        size = 13,\n",
    "        #size= rf.feature_importances_,\n",
    "        #color = np.random.randn(500), #set color equal to a variable\n",
    "        color = clf1.feature_importances_,\n",
    "        colorscale='Portland',\n",
    "        showscale=True\n",
    "    ),\n",
    "    text = surveyPd.columns.values\n",
    ")\n",
    "data = [trace]\n",
    "\n",
    "layout= go.Layout(\n",
    "    autosize= True,\n",
    "    title= 'Random Forest Feature Importance',\n",
    "    titlefont=dict(\n",
    "            size=40),\n",
    "    hovermode= 'closest',\n",
    "     xaxis= dict(\n",
    "         title = 'Question Number',\n",
    "         titlefont=dict(size=30),\n",
    "         ticklen= 1,\n",
    "         showgrid=False,\n",
    "        zeroline=False,\n",
    "        showline=False\n",
    "     ),\n",
    "    yaxis=dict(\n",
    "        title= 'Feature Importance',\n",
    "        titlefont=dict(size=30),\n",
    "        showgrid=False,\n",
    "        zeroline=False,\n",
    "        ticklen= 5,\n",
    "        gridwidth= 2\n",
    "    ),\n",
    "    showlegend= False\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig,filename='scatterrf1')\n",
    "fig.show(renderer=\"colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mVcXmb70D58A"
   },
   "source": [
    "#Ranking of important questions for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42709,
     "status": "aborted",
     "timestamp": 1618289446849,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "VedmA2dvIDBS"
   },
   "outputs": [],
   "source": [
    "#Here are the most important questions according to the RF algorithm\n",
    "\n",
    "rf_importances = clf1.feature_importances_\n",
    "rf_index = surveyPd.select_dtypes(include=num).columns.values \n",
    "#new_index = np.delete(rf_index, -1)\n",
    "\n",
    "featureimportance_df = pd.DataFrame({'Question Number': rf_index, 'Feature Importance': rf_importances}, columns=['Question Number', 'Feature Importance'])\n",
    "fi_df = featureimportance_df.sort_values(by=['Feature Importance'], ascending=False)\n",
    "fi_df\n",
    "\n",
    "top_five = fi_df.head(n=5)\n",
    "print(top_five)\n",
    "\n",
    "question_column = top_five.loc[:,'Question Number']\n",
    "\n",
    "imp_questions = question_column.values\n",
    "\n",
    "#returning the 5 most important questions\n",
    "\n",
    "print(\"The most important questions are: \")\n",
    "\n",
    "for i in imp_questions:\n",
    "  print(questions[int(i)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Gjb9aMRjHMK"
   },
   "source": [
    "## Hyper-Parameter Search for RF (K-Fold Cross Validation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42778,
     "status": "aborted",
     "timestamp": 1618289446923,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "10RQrCoVjPc6"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "#scores = cross_val_score(clf, surveyPd.loc[:,0:38], surveyPd[39], cv=5)\n",
    "scores = cross_val_score(clf1, X_train.select_dtypes(include=num), y_train,cv=5)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "# from sklearn.model_selection import cross_val_predict\n",
    "# predicted = cross_val_predict(clf1, surveyPd.loc[:,0:38], surveyPd[39], cv=10)\n",
    "# predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9AH5-wmUhvEI"
   },
   "source": [
    "# Hyper Parameter Search using Sklearn Grid Search Method for Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42778,
     "status": "aborted",
     "timestamp": 1618289446925,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "MsW0aVZYhxh8"
   },
   "outputs": [],
   "source": [
    "#Trying out Gradient Boosting\n",
    "#importing\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn import metrics\n",
    "\n",
    "#setting the gradient boosting parameter -- come back later if we need to change anything other than n_estimators\n",
    "gbm = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2XqhfZoniRE"
   },
   "source": [
    "# Hyper Parameter Search using Sklearn Grid Search Method for Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42777,
     "status": "aborted",
     "timestamp": 1618289446928,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "JR__5lB71CFz"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "gb_parameters = {\n",
    "    \"n_estimators\":[50,100], \n",
    "    'max_features':['auto',0.3],\n",
    "    \"max_depth\":[1,3,5],\n",
    "    \"random_state\":[42],\n",
    "    \"learning_rate\":[0.1,0.25],\n",
    "    \"loss\": ['deviance', 'exponential']\n",
    "}\n",
    "\n",
    "gbm1 = GridSearchCV(gbm, gb_parameters)\n",
    "gbm1.fit(X_train.select_dtypes(include=num),y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVYfHKMII2IE"
   },
   "source": [
    "# Gradient Boost Hyper Parameter Search Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42768,
     "status": "aborted",
     "timestamp": 1618289446929,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "dfvrgJgaUrF2"
   },
   "outputs": [],
   "source": [
    "gbm_results = pd.DataFrame.from_dict(gbm1.cv_results_)\n",
    "newdf = pd.DataFrame.from_dict(gbm1.cv_results_['params'])\n",
    "result = pd.concat([newdf,gbm_results], axis=1, join='inner')\n",
    "result.sort_values('rank_test_score', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zf_lSj3MI75L"
   },
   "source": [
    "# Fitting the best parameters on test data using Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42764,
     "status": "aborted",
     "timestamp": 1618289446930,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "UZ185Yqn82jN"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "#Fitting the model\n",
    "gbm2 = GradientBoostingClassifier(**gbm1.best_params_)\n",
    "gbm2.fit(X_train.select_dtypes(include=num), y_train)\n",
    "\n",
    "#Predicting based on the test set\n",
    "y_grad_predicted = gbm2.predict(X_test.select_dtypes(include=num))\n",
    "\n",
    "#printing full metrics report\n",
    "#print(metrics.classification_report(y_test, y_grad_predicted))\n",
    "print(classification_report(y_train, gbm2.predict(X_train.select_dtypes(include=num))))     \n",
    "print(classification_report(y_test, gbm2.predict(X_test.select_dtypes(include=num))))\n",
    "\n",
    "\n",
    "GB_roc_auc = roc_auc_score(y_test, gbm2.predict(X_test.select_dtypes(include=num)))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, gbm2.predict_proba(X_test.select_dtypes(include=num))[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Gradient Boost (area = %0.2f)' % GB_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Gradient Boost_ROC')\n",
    "plt.show()\n",
    "\n",
    "print('Confusion Matrix - Training Dataset')\n",
    "print(pd.crosstab(y_test.ravel(), y_grad_predicted, rownames = ['True'], colnames = ['Predicted'], margins = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-mp98Y4JBiT"
   },
   "source": [
    "# Feature Importance Visual as Determined by Gradient Boost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42758,
     "status": "aborted",
     "timestamp": 1618289446931,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "QlfZGJVdJGA2"
   },
   "outputs": [],
   "source": [
    "# Scatter plot \n",
    "trace = go.Scatter(\n",
    "    y = gbm2.feature_importances_,\n",
    "    x = surveyPd.columns.values,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        sizemode = 'diameter',\n",
    "        sizeref = 1,\n",
    "        size = 13,\n",
    "        #size= rf.feature_importances_,\n",
    "        #color = np.random.randn(500), #set color equal to a variable\n",
    "        color = gbm2.feature_importances_,\n",
    "        colorscale='Portland',\n",
    "        showscale=True\n",
    "    ),\n",
    "    text = surveyPd.columns.values\n",
    ")\n",
    "data = [trace]\n",
    "\n",
    "layout= go.Layout(\n",
    "    autosize= True,\n",
    "    title= 'Gradient Boost Feature Importance',\n",
    "    hovermode= 'closest',\n",
    "     xaxis= dict(\n",
    "         ticklen= 1,\n",
    "         showgrid=False,\n",
    "        zeroline=False,\n",
    "        showline=False\n",
    "     ),\n",
    "    yaxis=dict(\n",
    "        title= 'Feature Importance',\n",
    "        showgrid=False,\n",
    "        zeroline=False,\n",
    "        ticklen= 5,\n",
    "        gridwidth= 2\n",
    "    ),\n",
    "    showlegend= False\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig,filename='scattergb')\n",
    "fig.show(renderer=\"colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42755,
     "status": "aborted",
     "timestamp": 1618289446932,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "N00c6LO8gpfw"
   },
   "outputs": [],
   "source": [
    "#Here are the most important questions according to the GB algorithm\n",
    "\n",
    "gb_importances = gbm2.feature_importances_\n",
    "gb_index = surveyPd.select_dtypes(include=num).columns.values \n",
    "#new_index = np.delete(rf_index, -1)\n",
    "\n",
    "featureimportance_df = pd.DataFrame({'Question Number': gb_index, 'Feature Importance': gb_importances}, columns=['Question Number', 'Feature Importance'])\n",
    "fi_df = featureimportance_df.sort_values(by=['Feature Importance'], ascending=False)\n",
    "fi_df\n",
    "\n",
    "top_five = fi_df.head(n=5)\n",
    "print(top_five)\n",
    "\n",
    "question_column = top_five.loc[:,'Question Number']\n",
    "\n",
    "imp_questions = question_column.values\n",
    "\n",
    "#returning the 5 most important questions\n",
    "\n",
    "#print(imp_questions)\n",
    "print('The questions are:')\n",
    "for i in imp_questions:\n",
    "  print(questions[int(i)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rq8J_cLjJHmS"
   },
   "source": [
    "# K Fold Cross Validation on the Gradient Boost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42750,
     "status": "aborted",
     "timestamp": 1618289446933,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "FF4FqTptFh2W"
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(gbm2, X_train.select_dtypes(include=num), y_train,cv=5)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "predicted = cross_val_predict(gbm2, X_train.select_dtypes(include=num), y_train, cv=10)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLz0SG_NokCb"
   },
   "source": [
    "# Hyper Parameter Search using Sklearn Grid Search Method for Xtreme Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42747,
     "status": "aborted",
     "timestamp": 1618289446934,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "_mbk9-25om-M"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgm = XGBClassifier()\n",
    "\n",
    "#try a more different learning rates and other parameter values\n",
    "xgm_parameters = {\n",
    "    \"n_estimators\":[50,100,200], \n",
    "    'max_features':[1, 10,'auto','sqrt'],\n",
    "    \"max_depth\":[1,3,5],\n",
    "    \"random_state\":[42],\n",
    "    \"learning_rate\":[0.05,0.1,0.25],\n",
    "    \n",
    "}\n",
    "xgm1 = GridSearchCV(xgm, xgm_parameters)\n",
    "xgm1.fit(X_train.select_dtypes(include=num),y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zr-KMFJPJNH8"
   },
   "source": [
    "# Hyper Parameter Experiment Results using XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42742,
     "status": "aborted",
     "timestamp": 1618289446935,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "Nt3cp-66VdAo"
   },
   "outputs": [],
   "source": [
    "xgm_results = pd.DataFrame.from_dict(xgm1.cv_results_)\n",
    "newdf = pd.DataFrame.from_dict(xgm1.cv_results_['params'])\n",
    "result = pd.concat([newdf,xgm_results], axis=1, join='inner')\n",
    "result.sort_values('rank_test_score', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFUz2vc_JUPP"
   },
   "source": [
    "# Testing Best Parameters from HP search on Test Data using XGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42736,
     "status": "aborted",
     "timestamp": 1618289446935,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "GZ1ypJMIpLzt"
   },
   "outputs": [],
   "source": [
    "#XGboost\n",
    "from xgboost import XGBClassifier\n",
    "xgm2 = XGBClassifier(**xgm1.best_params_)\n",
    "\n",
    "xgm2.fit(X_train.select_dtypes(include=num), y_train)\n",
    "\n",
    "y_xg_predicted = xgm2.predict(X_test.select_dtypes(include=num))\n",
    "\n",
    "#print(metrics.classification_report(y_test, y_xg_predicted))\n",
    "print(classification_report(y_train, xgm2.predict(X_train.select_dtypes(include=num))))     \n",
    "print(classification_report(y_test, xgm2.predict(X_test.select_dtypes(include=num))))\n",
    "\n",
    "XGB_roc_auc = roc_auc_score(y_test, xgm2.predict(X_test.select_dtypes(include=num)))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, xgm2.predict_proba(X_test.select_dtypes(include=num))[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='X Gradient Boost (area = %0.2f)' % XGB_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('XGB_ROC')\n",
    "plt.show()\n",
    "\n",
    "print('Confusion Matrix - Training Dataset')\n",
    "print(pd.crosstab(y_test.ravel(), y_xg_predicted, rownames = ['True'], colnames = ['Predicted'], margins = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gs1GF5XhJfyj"
   },
   "source": [
    "# Feature Importance Visual from XGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42735,
     "status": "aborted",
     "timestamp": 1618289446936,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "oN5Su9gcJl-z"
   },
   "outputs": [],
   "source": [
    "# Scatter plot \n",
    "trace = go.Scatter(\n",
    "    y = xgm2.feature_importances_,\n",
    "    x = surveyPd.columns.values,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        sizemode = 'diameter',\n",
    "        sizeref = 1,\n",
    "        size = 13,\n",
    "        #size= rf.feature_importances_,\n",
    "        #color = np.random.randn(500), #set color equal to a variable\n",
    "        color = xgm2.feature_importances_,\n",
    "        colorscale='Portland',\n",
    "        showscale=True\n",
    "    ),\n",
    "    text = surveyPd.columns.values\n",
    ")\n",
    "data = [trace]\n",
    "\n",
    "layout= go.Layout(\n",
    "    autosize= True,\n",
    "    title= 'XG Boost Feature Importance',\n",
    "    hovermode= 'closest',\n",
    "     xaxis= dict(\n",
    "         ticklen= 1,\n",
    "         showgrid=False,\n",
    "        zeroline=False,\n",
    "        showline=False\n",
    "     ),\n",
    "    yaxis=dict(\n",
    "        title= 'Feature Importance',\n",
    "        showgrid=False,\n",
    "        zeroline=False,\n",
    "        ticklen= 5,\n",
    "        gridwidth= 2\n",
    "    ),\n",
    "    showlegend= False\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig,filename='scatterxg')\n",
    "fig.show(renderer=\"colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42741,
     "status": "aborted",
     "timestamp": 1618289446944,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "lnaWG8sziJ-h"
   },
   "outputs": [],
   "source": [
    "#Here are the most important questions according to the RF algorithm\n",
    "\n",
    "xg_importances = xgm2.feature_importances_\n",
    "xg_index = surveyPd.select_dtypes(include=num).columns.values \n",
    "#new_index = np.delete(rf_index, -1)\n",
    "\n",
    "featureimportance_df = pd.DataFrame({'Question Number': xg_index, 'Feature Importance': xg_importances}, columns=['Question Number', 'Feature Importance'])\n",
    "fi_df = featureimportance_df.sort_values(by=['Feature Importance'], ascending=False)\n",
    "fi_df\n",
    "\n",
    "top_five = fi_df.head(n=5)\n",
    "print(top_five)\n",
    "\n",
    "question_column = top_five.loc[:,'Question Number']\n",
    "\n",
    "imp_questions = question_column.values\n",
    "\n",
    "#returning the 5 most important questions\n",
    "\n",
    "print(imp_questions)\n",
    "\n",
    "for i in imp_questions:\n",
    "  print(questions[int(i)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXiE76UAJovj"
   },
   "source": [
    "# K Fold Cross Validation on the XGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42741,
     "status": "aborted",
     "timestamp": 1618289446945,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "hiSRiDJKFuXE"
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(xgm2, X_train.select_dtypes(include=num), y_train,cv=5)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "predicted = cross_val_predict(xgm2, X_train.select_dtypes(include=num), y_train, cv=10)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4s43-ukJ2tf"
   },
   "source": [
    "# AUTO KERAS MODELLING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dEu7Izs6IRW4"
   },
   "source": [
    "# Using Auto Keras to build a Classification Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42738,
     "status": "aborted",
     "timestamp": 1618289446945,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "KiV3PqJ9AJC_"
   },
   "outputs": [],
   "source": [
    "\n",
    "#AutoKeras\n",
    "#Try this with a different loss function\n",
    "\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import autokeras as ak\n",
    "\n",
    "\n",
    "#fitting the model\n",
    "alf = ak.StructuredDataClassifier(max_trials=5, loss=\"binary_crossentropy\")\n",
    "alf.fit(X_train,y_train, verbose=1, epochs=10)\n",
    "\n",
    "alf_eval = alf.evaluate(X_train, y_train)\n",
    "alf_eval\n",
    "\n",
    "\n",
    "#alf_predict = alf.predict(X_test)\n",
    "#cm = confusion_matrix(y_test,alf_predict)\n",
    "#sns.heatmap(cm, annot=True)\n",
    "\n",
    "model = alf.export_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-SzRCKaf20y"
   },
   "source": [
    "Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5KugpzUss4N"
   },
   "source": [
    "# Class Weight Experiment with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42738,
     "status": "aborted",
     "timestamp": 1618289446946,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "TO5mw3QpiIHE"
   },
   "outputs": [],
   "source": [
    "#checking the shape of our data\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42737,
     "status": "aborted",
     "timestamp": 1618289446946,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "qmnXy5jie4FS"
   },
   "outputs": [],
   "source": [
    "counts = np.bincount(y_train)\n",
    "print(\n",
    "    \"Number of positive samples in training data: {} ({:.2f}% of total)\".format(\n",
    "        counts[1], 100 * float(counts[1]) / len(y_train)\n",
    "    )\n",
    ")\n",
    "\n",
    "#Determining the weight needed for each class\n",
    "##This could be changed if we wished to weight the attriting class even more strongly\n",
    "weight_for_0 = 1.0 / counts[0]\n",
    "weight_for_1 = 1.0 / counts[1]\n",
    "\n",
    "print(\"Weight for neg class\", weight_for_0)\n",
    "print(\"Weight for attrit class\", weight_for_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42737,
     "status": "aborted",
     "timestamp": 1618289446948,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "V76LVrw4GhTO"
   },
   "outputs": [],
   "source": [
    "#trying regular keras based on this credit card fraud example- https://keras.io/examples/structured_data/imbalanced_classification/\n",
    "#class weight serves to make the loss function pay more attention to a miss\n",
    "from tensorflow import keras\n",
    "\n",
    "#defining the model\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(\n",
    "            256, activation=\"relu\", input_shape=(X_train.shape[-1],)\n",
    "        ),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42735,
     "status": "aborted",
     "timestamp": 1618289446949,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "BIq4RXT-d68R"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "metrics = [\n",
    "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    keras.metrics.TruePositives(name=\"tp\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\"),\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-2), loss=\"binary_crossentropy\", metrics=metrics\n",
    ")\n",
    "\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(\"atrrit_model_at_epoch_{epoch}.h5\")]\n",
    "class_weight = {0:weight_for_0, 1:weight_for_1} #adjust this to determine the penalty for missing\n",
    "\n",
    "model.fit(X_train,y_train,\n",
    "    batch_size=2048,\n",
    "    epochs=10,\n",
    "    verbose=2,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(X_test, y_test),\n",
    "    class_weight=class_weight\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42734,
     "status": "aborted",
     "timestamp": 1618289446949,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "gs6ljtJpoAMc"
   },
   "outputs": [],
   "source": [
    "# np.set_printoptions(precision=4, suppress=True)\n",
    "from sklearn import metrics\n",
    "# eval_results = model.evaluate(X_test, y_test, verbose=0) \n",
    "\n",
    "# print(\"\\nLoss, accuracy on test data: \")\n",
    "# print(\"%0.4f, %0.2f%%\" % (eval_results[0], \\\n",
    "#   eval_results[1]*100))\n",
    "\n",
    "keras_predicted = model.predict(X_test)\n",
    "\n",
    "\n",
    "y_pred = np.argmax(keras_predicted, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print('Classification Report')\n",
    "target_names = ['Stay','Attrit']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "#print(metrics.classification_report(y_test, keras_predicted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cnZPPk1TsX4P"
   },
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpIfAduysc75"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "Questions that were asked to the recipients of Client #1's survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42731,
     "status": "aborted",
     "timestamp": 1618289446950,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "0fCqEDSTKpo7"
   },
   "outputs": [],
   "source": [
    "q_cols = ['general empl satisfaction',\n",
    " 'recommend empl unit to friend',\n",
    " 'motivation of direct colleagues you are working with day to day? *Top 3',\n",
    " 'My direct colleagues are coping well with the change and transformation in our division/function',\n",
    " 'People in my team frequently go above and beyond the requirements of the job',\n",
    " 'I am proud working for my company and gladly tell people about it',\n",
    " 'I believe strongly in and support the future direction of my company',\n",
    " 'I trust that my company takes action that balances the best interests of our people, business and clients',\n",
    " \"My company's handling of this year’s challenges leaves me confident in our future success\",\n",
    " \"My company's future direction leaves me confident about my career opportunities here\",\n",
    " 'In my team we continuously use client feedback to improve our products/services',\n",
    " 'In my team we have an ongoing dialogue about our clients and their requirements and expectations',\n",
    " 'Compared to last year, our clients now view us as:',\n",
    " 'My immediate manager creates an atmosphere of openness and trust',\n",
    " 'I have confidence in my immediate manager',\n",
    " 'I have confidence in the global senior management of [division]',\n",
    " 'I have confidence in the senior management of [FUNCTION: Finance, HR, Technology, Operations, Marketing]',\n",
    " 'I have confidence in my local/country senior management',\n",
    " 'As a member of [FUNCTION: Finance, HR, Technology, Operations, Marketing] I am familiar with the overall objectives & strategies of my function',\n",
    " 'I am familiar with the overall objectives & strategies of [division]',\n",
    " 'I can clearly see how my own work contributes to the overall objectives & strategies of [division]',\n",
    " 'In my team we work towards clear objectives',\n",
    " 'In my team we make decisions rapidly when it is necessary',\n",
    " 'In my team actions are taken quickly when decisions have been made',\n",
    " 'Please rate the cooperation between different units within [division]',\n",
    " 'Please rate the cooperation within [FUNCTION: Finance, HR, Technology, Operations, Marketing]',\n",
    " 'Please rate the cooperation across the company as a whole',\n",
    " 'In my team new ideas receive very strong support and encouragement',\n",
    " 'I feel I can make my own decisions concerning my work',\n",
    " \"I have seen action taken based on the results of last year's survey\",\n",
    " 'In my company diversity of skills, experiences, background and ways of working are recognized and appreciated',\n",
    " 'My immediate manager treats all team members fairly, regardless of age, gender identity, sex, family status, race, national origin, nationality, religion, disability or sexual orientation',\n",
    " 'My immediate manager effectively works with people who are different from them to achieve business results',\n",
    " 'In my team we treat each other fairly, regardless of age, sex, gender identity, family status, race, national origin, nationality, religion, disability or sexual orientation',\n",
    " 'I feel included in my team',\n",
    " 'My company takes an interest in my well-being',\n",
    " 'My work schedule allows me sufficient flexibility to meet my personal/family needs',\n",
    " 'Career opportunities always go to the most qualified person regardless of age, gender identity, sex, family status, race, national origin, nationality, religion, disability or sexual orientation',\n",
    " 'Is there anything else you want to share with us?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PteRb98iq7a0"
   },
   "source": [
    "#Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42731,
     "status": "aborted",
     "timestamp": 1618289446951,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "eKbFDlRuetxr"
   },
   "outputs": [],
   "source": [
    "#one hot encoding is built into this model. do not need to use it in the preprocessing\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn import metrics\n",
    "from catboost.utils import get_confusion_matrix\n",
    "\n",
    "#train the model\n",
    "\n",
    "train_dataset = Pool(data=X_train,\n",
    "                     label=y_train)\n",
    "\n",
    "eval_dataset = Pool(data=X_test,\n",
    "                    label=y_test)\n",
    "\n",
    "\n",
    "cbm = CatBoostClassifier(verbose=200, loss_function='Logloss', eval_metric='AUC',random_seed=42)\n",
    "\n",
    "cbm.fit(train_dataset, use_best_model=True, eval_set=eval_dataset, plot=True)\n",
    "\n",
    "\n",
    "cat_predict = cbm.predict(X_test)\n",
    "\n",
    "print(cat_predict)\n",
    "\n",
    "cm1 = get_confusion_matrix(cbm, Pool(X_train, y_train))\n",
    "print(cm1)\n",
    "\n",
    "cm2 = get_confusion_matrix(cbm, Pool(X_test, y_test))\n",
    "print(cm2)\n",
    "\n",
    "print(cbm.get_best_score())\n",
    "print(cbm.get_best_iteration())\n",
    "\n",
    "print(\"Count of trees in model = {}\".format(cbm.tree_count_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuucWo5_r-xe"
   },
   "source": [
    "#Hyper Parameter Search using Sklearn Grid Search Method for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42730,
     "status": "aborted",
     "timestamp": 1618289446952,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "tYJoCF4thTgo"
   },
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "svm_parameters = {'kernel':('linear', 'rbf'), 'C':[1,5]} #added a class weight\n",
    "svc = svm.SVC()\n",
    "clf2 = GridSearchCV(svc, svm_parameters)\n",
    "clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FfoD5AOGIaz0"
   },
   "source": [
    "# Hyper Parameter Results for SVM\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42729,
     "status": "aborted",
     "timestamp": 1618289446952,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "zfq6fPEYqBuN"
   },
   "outputs": [],
   "source": [
    "svm_results = pd.DataFrame.from_dict(clf2.cv_results_)\n",
    "newdf = pd.DataFrame.from_dict(clf2.cv_results_['params'])\n",
    "result = pd.concat([newdf,svm_results], axis=1, join='inner')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzqRC3wbIf0D"
   },
   "source": [
    "# Best Parameters Chosen for SVM on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42729,
     "status": "aborted",
     "timestamp": 1618289446954,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "N5iLwdYT8bWd"
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf3 = svm.SVC(**clf2.best_params_).fit(X_train, y_train)\n",
    "clf3.score(X_test, y_test)\n",
    "print(classification_report(y_train, clf3.predict(X_train)))\n",
    "      \n",
    "print(classification_report(y_test, clf3.predict(X_test)))\n",
    "\n",
    "plot_roc_curve(clf3, X_test, y_test)\n",
    "print('Confusion Matrix - Training Dataset')\n",
    "print(pd.crosstab(y_test.ravel(),  clf3.predict(X_test), rownames = ['True'], colnames = ['Predicted'], margins = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mp4WFfX5IuUU"
   },
   "source": [
    "# K-Fold Cross Validation of SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42729,
     "status": "aborted",
     "timestamp": 1618289446955,
     "user": {
      "displayName": "Kelly Hain",
      "photoUrl": "",
      "userId": "08494635066290375739"
     },
     "user_tz": 240
    },
    "id": "-Utzf69pf53F"
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(clf3, X_train, y_train,cv=5)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "predicted = cross_val_predict(clf3, X_train, y_train, cv=10)\n",
    "predicted"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Benchmark.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "24d0e800c9d34745852f3e3ab5cf7520": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c96c755a8e3c446a843d3173a02ce48c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cbe07ec20ce542e4878516d189f8ef49": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DropdownModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DropdownModel",
      "_options_labels": [
       "K_Survey",
       "K_Survey_Org",
       "Q1_2018",
       "Q3_2018",
       "Q1_2019",
       "Q3_2019",
       "Q1_2020"
      ],
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "DropdownView",
      "description": "File Name:",
      "description_tooltip": null,
      "disabled": false,
      "index": 3,
      "layout": "IPY_MODEL_24d0e800c9d34745852f3e3ab5cf7520",
      "style": "IPY_MODEL_c96c755a8e3c446a843d3173a02ce48c"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
